# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HQNd0el7WOp6ajdQRk5TuWha2g6wbL0K
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
import json
import matplotlib.animation as animation

# convert an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return np.array(dataX), np.array(dataY)

# fix random seed for reproducibility
tf.random.set_seed(7)

# load the dataset from JSON
with open('BTCUSDT_1D.json') as f:
    data = json.load(f)

# Extract 'close' prices and dates
close_prices = [float(item[4]) for item in data]
dates = [pd.to_datetime(item[0], unit='ms') for item in data]

# Convert to DataFrame
dataframe = pd.DataFrame(close_prices, columns=['Close'], index=dates)
dataset = dataframe.values
dataset = dataset.astype('float32')

# normalize the dataset
scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)

# split into train and test sets
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]

# reshape into X=t and Y=t+1
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)

# reshape input to be [samples, time steps, features]
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

# create and fit the LSTM network
model = Sequential()
model.add(LSTM(4, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)

# forecasting next 3 days
input_seq = dataset[-look_back:].reshape((1, 1, look_back))
future_predictions = []
for _ in range(3):
    next_pred = model.predict(input_seq)
    future_predictions.append(next_pred[0, 0])
    input_seq = np.append(input_seq[:, :, 1:], next_pred.reshape(1, 1, 1), axis=2)

# invert future predictions
future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

# generate dates for future predictions
future_dates = pd.date_range(start=dataframe.index[-1], periods=4, inclusive='right').to_pydatetime().tolist()

# creating the animated plot
fig, ax = plt.subplots()
ax.plot(dates, scaler.inverse_transform(dataset), label='Original Data')
line, = ax.plot([], [], 'r-', label='Prediction')

# creating the animated plot
fig, ax = plt.subplots()
ax.plot(dates, scaler.inverse_transform(dataset), label='Original Data')
line, = ax.plot([], [], 'r-', label='Prediction')

def init():
    ax.set_xlim(dates[0], future_dates[-1])  # Definir limites do eixo x para cobrir todos os dados
    ax.set_ylim(np.min(scaler.inverse_transform(dataset)), np.max(future_predictions) * 1.1)  # Ajustar limites do eixo y
    line.set_data([], [])
    return line,

def update(frame):
    xdata = np.concatenate((dates, future_dates[:frame + 1]))
    ydata = np.concatenate((scaler.inverse_transform(dataset).flatten(), future_predictions[:frame + 1].flatten()))
    line.set_data(xdata, ydata)
    return line,

ani = animation.FuncAnimation(fig, update, frames=range(4), init_func=init, blit=True, repeat=False)  # Ajuste o número de frames para incluir as previsões futuras
plt.legend()
plt.show()

# Save the animation as a GIF
ani.save('forecast_animation.gif', writer='imagemagick', fps=1)

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from sklearn.preprocessing import MinMaxScaler
import json

# convert an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return np.array(dataX), np.array(dataY)

# fix random seed for reproducibility
tf.random.set_seed(7)

# load the dataset from JSON
with open('BTCUSDT_1D.json') as f:
    data = json.load(f)

# Extract 'close' prices and dates
close_prices = [float(item[4]) for item in data]
dates = [pd.to_datetime(item[0], unit='ms') for item in data]

# Convert to DataFrame
dataframe = pd.DataFrame(close_prices, columns=['Close'], index=dates)
dataset = dataframe.values
dataset = dataset.astype('float32')

# normalize the dataset
scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)

# split into train and test sets
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]

# reshape into X=t and Y=t+1
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)

# reshape input to be [samples, time steps, features]
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

# create and fit the LSTM network
model = Sequential()
model.add(LSTM(4, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)

# forecasting next 3 days
input_seq = dataset[-look_back:].reshape((1, 1, look_back))
future_predictions = []
for _ in range(3):
    next_pred = model.predict(input_seq)
    future_predictions.append(next_pred[0, 0])
    input_seq = np.append(input_seq[:, :, 1:], next_pred.reshape(1, 1, 1), axis=2)

# invert future predictions
future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

# generate dates for future predictions
future_dates = pd.date_range(start=dataframe.index[-1], periods=3, freq='D').to_pydatetime().tolist()

# Plot original data and predictions
plt.figure(figsize=(10, 6))
plt.plot(dates, scaler.inverse_transform(dataset), label='Original Data')
plt.plot(future_dates, future_predictions, 'r--', label='Future Predictions')
for i, pred in enumerate(future_predictions):
    plt.text(future_dates[i], pred, f'{pred[0]:.2f}', ha='center', va='bottom', fontsize=10)
plt.title('BTC Price Forecasting')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.grid(True)
plt.show()

future_predictions

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from sklearn.preprocessing import MinMaxScaler
import json
import matplotlib.animation as animation

# Convert an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return np.array(dataX), np.array(dataY)

# Fix random seed for reproducibility
tf.random.set_seed(7)

# Load the dataset from JSON
with open('BTCUSDT_1D.json') as f:
    data = json.load(f)

# Extract 'close' prices and dates
close_prices = [float(item[4]) for item in data]
dates = [pd.to_datetime(item[0], unit='ms') for item in data]

# Convert to DataFrame
dataframe = pd.DataFrame(close_prices, columns=['Close'], index=dates)
dataset = dataframe.values.astype('float32')

# Normalize the dataset
scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)

# Split into train and test sets
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]

# Reshape into X=t and Y=t+1
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)

# Reshape input to be [samples, time steps, features]
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

# Create and fit the LSTM network
model = Sequential()
model.add(LSTM(4, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)

# Forecasting next 3 days
input_seq = dataset[-look_back:].reshape((1, 1, look_back))
future_predictions = []
for _ in range(3):
    next_pred = model.predict(input_seq)
    future_predictions.append(next_pred[0, 0])
    input_seq = np.append(input_seq[:, :, 1:], next_pred.reshape(1, 1, 1), axis=2)

# Invert future predictions
future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

# Generate dates for future predictions
future_dates = pd.date_range(start=dataframe.index[-1], periods=4, inclusive='right').to_pydatetime().tolist()

# Creating the animated plot
fig, ax = plt.subplots(figsize=(12, 6))  # Aumentar o tamanho do gráfico
ax.plot(dates, scaler.inverse_transform(dataset), label='Original Data')
line, = ax.plot([], [], 'r-', label='Prediction')

def init():
    ax.set_xlim(dates[0], future_dates[-1])  # Set x-axis limits to cover all data
    ax.set_ylim(np.min(scaler.inverse_transform(dataset)) * 0.95, np.max(future_predictions) * 1.05)  # Adjust y-axis limits
    line.set_data([], [])
    return line,

def update(frame):
    xdata = np.concatenate((dates, future_dates[:frame + 1]))
    ydata = np.concatenate((scaler.inverse_transform(dataset).flatten(), future_predictions[:frame + 1].flatten()))
    line.set_data(xdata, ydata)
    return line,

ani = animation.FuncAnimation(fig, update, frames=range(4), init_func=init, blit=True, repeat=False)  # Adjust number of frames to include future predictions
plt.legend()
plt.show()

# Save the animation as a GIF
ani.save('forecast_animation.gif', writer='pillow', fps=1)

# Mostrar valores previstos
future_predictions_values = future_predictions.flatten()
print(f"Previsões futuras: {future_predictions_values}")

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from sklearn.preprocessing import MinMaxScaler
import json
import matplotlib.animation as animation

# Convert an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return np.array(dataX), np.array(dataY)

# Fix random seed for reproducibility
tf.random.set_seed(7)

# Load the dataset from JSON
with open('BTCUSDT_1D.json') as f:
    data = json.load(f)

# Extract 'close' prices and dates
close_prices = [float(item[4]) for item in data]
dates = [pd.to_datetime(item[0], unit='ms') for item in data]

# Convert to DataFrame
dataframe = pd.DataFrame(close_prices, columns=['Close'], index=dates)
dataset = dataframe.values.astype('float32')

# Normalize the dataset
scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)

# Split into train and test sets
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]

# Reshape into X=t and Y=t+1
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)

# Reshape input to be [samples, time steps, features]
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

# Create and fit the LSTM network
model = Sequential()
model.add(LSTM(4, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)

# Forecasting next 3 days
input_seq = dataset[-look_back:].reshape((1, 1, look_back))
future_predictions = []
for _ in range(3):
    next_pred = model.predict(input_seq)
    future_predictions.append(next_pred[0, 0])
    input_seq = np.append(input_seq[:, :, 1:], next_pred.reshape(1, 1, 1), axis=2)

# Invert future predictions
future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

# Generate dates for future predictions
future_dates = pd.date_range(start=dataframe.index[-1], periods=4, inclusive='right').to_pydatetime().tolist()

# Creating the animated plot
fig, ax = plt.subplots(figsize=(12, 6))  # Aumentar o tamanho do gráfico
ax.plot(dates, scaler.inverse_transform(dataset), label='Original Data')
line, = ax.plot([], [], 'r-', label='Prediction')

def init():
    ax.set_xlim(dates[0], future_dates[-1])  # Set x-axis limits to cover all data
    ax.set_ylim(0, 70000)  # Ajustar os limites do eixo y para ir até 70.000
    line.set_data([], [])
    return line,

def update(frame):
    xdata = np.concatenate((dates, future_dates[:frame + 1]))
    ydata = np.concatenate((scaler.inverse_transform(dataset).flatten(), future_predictions[:frame + 1].flatten()))
    line.set_data(xdata, ydata)
    return line,

ani = animation.FuncAnimation(fig, update, frames=range(4), init_func=init, blit=True, repeat=False)  # Adjust number of frames to include future predictions
plt.legend()
plt.show()

# Save the animation as a GIF
ani.save('forecast_animation.gif', writer='pillow', fps=1)

# Mostrar valores previstos
future_predictions_values = future_predictions.flatten()
print(f"Previsões futuras: {future_predictions_values}")