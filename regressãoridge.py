# -*- coding: utf-8 -*-
"""RegressãoRidge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XDAO5hlYuGZ_f7p8MMUZlQzZbmr6G_Bi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

# Load the CSV data (ensure the file path is correct)
data = pd.read_csv('BTCUSDT_1D (2).csv')

# Convert the 'date_time' column to Unix timestamp
data['date_time'] = pd.to_datetime(data['date_time'], dayfirst=True).view(int) // 10**9

# Identify categorical columns
categorical_cols = data.select_dtypes(include=['object']).columns

# Convert categorical columns to numerical using one-hot encoding
data = pd.get_dummies(data, columns=categorical_cols)

# Handle missing values by imputing with column mean
data.fillna(data.mean(), inplace=True)

# Separate the independent variables (X) and the dependent variable (y)
X = data.drop(columns=['close'])  # Independent columns (except 'close')
y = data['close']  # 'close' column as dependent variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create the Ridge regression model
alpha = 1.0  # Regularization hyperparameter (adjust as needed)
ridge_model = Ridge(alpha=alpha)

# Train the model
ridge_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = ridge_model.predict(X_test)

# Evaluate the model performance (mean squared error)
mse = mean_squared_error(y_test, y_pred)
print(f'MSE: {mse:.2f}')

# Visualize the results in a plot
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='blue', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')
plt.xlabel('Valor Real')
plt.ylabel('Valor Previsto')
plt.title('Regressão de Ridge - Valor Real vs. Valor Previsto')
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

# Load the CSV data (ensure the file path is correct)
data = pd.read_csv('BTCUSDT_1D (2).csv')

# Convert the 'date_time' column to Unix timestamp
data['date_time'] = pd.to_datetime(data['date_time'], dayfirst=True).view(int) // 10**9

# Identify categorical columns
categorical_cols = data.select_dtypes(include=['object']).columns

# Convert categorical columns to numerical using one-hot encoding
data = pd.get_dummies(data, columns=categorical_cols)

# Handle missing values by imputing with column mean
data.fillna(data.mean(), inplace=True)

# Separate the independent variables (X) and the dependent variable (y)
X = data.drop(columns=['close'])  # Independent columns (except 'close')
y = data['close']  # 'close' column as dependent variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create the Ridge regression model
alpha = 1.0  # Regularization hyperparameter (adjust as needed)
ridge_model = Ridge(alpha=alpha)

# Train the model
ridge_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = ridge_model.predict(X_test)

# Evaluate the model performance (mean squared error)
mse = mean_squared_error(y_test, y_pred)
print(f'MSE: {mse:.2f}')

# Convert the 'date_time' column back to datetime for plotting
data['date_time'] = pd.to_datetime(data['date_time'], unit='s')

# Merge predictions with the test set for plotting
test_data = X_test.copy()
test_data['date_time'] = data.loc[X_test.index, 'date_time']
test_data['Actual'] = y_test
test_data['Predicted'] = y_pred

# Sort the data by date_time for proper plotting
test_data.sort_values(by='date_time', inplace=True)

# Visualize the results in a plot
plt.figure(figsize=(14, 8))
plt.plot(test_data['date_time'], test_data['Actual'], label='Valor Real', color='blue')
plt.plot(test_data['date_time'], test_data['Predicted'], label='Valor Previsto', color='red', linestyle='--')
plt.xlabel('Data')
plt.ylabel('Valor')
plt.title('Comparação de Valores Reais e Previstos ao Longo do Tempo')
plt.legend()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

# Load the CSV data (ensure the file path is correct)
data = pd.read_csv('BTCUSDT_1D (2).csv')

# Convert the 'date_time' column to Unix timestamp
data['date_time'] = pd.to_datetime(data['date_time'], dayfirst=True).view(int) // 10**9

# Identify categorical columns
categorical_cols = data.select_dtypes(include=['object']).columns

# Convert categorical columns to numerical using one-hot encoding
data = pd.get_dummies(data, columns=categorical_cols)

# Handle missing values by imputing with column mean
data.fillna(data.mean(), inplace=True)

# Separate the independent variables (X) and the dependent variable (y)
X = data.drop(columns=['close'])  # Independent columns (except 'close')
y = data['close']  # 'close' column as dependent variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create the Ridge regression model
alpha = 1.0  # Regularization hyperparameter (adjust as needed)
ridge_model = Ridge(alpha=alpha)

# Train the model
ridge_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = ridge_model.predict(X_test)

# Evaluate the model performance (mean squared error)
mse = mean_squared_error(y_test, y_pred)
print(f'MSE: {mse:.2f}')

# Convert the 'date_time' column back to datetime for plotting
data['date_time'] = pd.to_datetime(data['date_time'], unit='s')

# Merge predictions with the test set for plotting
test_data = X_test.copy()
test_data['date_time'] = data.loc[X_test.index, 'date_time']
test_data['Actual'] = y_test
test_data['Predicted'] = y_pred

# Sort the data by date_time for proper plotting
test_data.sort_values(by='date_time', inplace=True)

# Visualize the results in a plot
plt.figure(figsize=(14, 8))
plt.plot(test_data['date_time'], test_data['Actual'], label='Valor Real', color='blue')
plt.plot(test_data['date_time'], test_data['Predicted'], label='Valor Previsto', color='red', linestyle='--')
plt.xlabel('Data')
plt.ylabel('Valor')
plt.title('Comparação de Valores Reais e Previstos ao Longo do Tempo')
plt.legend()
plt.show()

# Predict the next 4 days' closing values
predictions = []
last_date = data['date_time'].max()

# Prepare the initial feature set for the next day's prediction
next_day_features = data.iloc[-1].copy()

for i in range(1, 5):
    next_date = last_date + pd.Timedelta(days=i)
    next_date_unix = next_date.value // 10**9

    # Update the date_time for the next day
    next_day_features['date_time'] = next_date_unix

    # Convert the features to a DataFrame
    next_day_features_df = pd.DataFrame([next_day_features])

    # Make the prediction
    next_day_prediction = ridge_model.predict(next_day_features_df.drop(columns=['close']))[0]

    # Store the prediction
    predictions.append((next_date, next_day_prediction))

    # Update the features for the next iteration
    next_day_features['close'] = next_day_prediction

# Print predictions for the next 4 days
for date, prediction in predictions:
    print(f'Previsão para {date.date()}: {prediction:.2f}')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

# Load the CSV data (ensure the file path is correct)
data = pd.read_csv('BTCUSDT_1D (2).csv')

# Convert the 'date_time' column to Unix timestamp
data['date_time'] = pd.to_datetime(data['date_time'], dayfirst=True).view(int) // 10**9

# Identify categorical columns
categorical_cols = data.select_dtypes(include=['object']).columns

# Convert categorical columns to numerical using one-hot encoding
data = pd.get_dummies(data, columns=categorical_cols)

# Handle missing values by imputing with column mean
data.fillna(data.mean(), inplace=True)

# Separate the independent variables (X) and the dependent variable (y)
X = data.drop(columns=['close'])  # Independent columns (except 'close')
y = data['close']  # 'close' column as dependent variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create the Ridge regression model
alpha = 1.0  # Regularization hyperparameter (adjust as needed)
ridge_model = Ridge(alpha=alpha)

# Train the model
ridge_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = ridge_model.predict(X_test)

# Evaluate the model performance (mean squared error)
mse = mean_squared_error(y_test, y_pred)
print(f'MSE: {mse:.2f}')

# Convert the 'date_time' column back to datetime for plotting
data['date_time'] = pd.to_datetime(data['date_time'], unit='s')

# Merge predictions with the test set for plotting
test_data = X_test.copy()
test_data['date_time'] = data.loc[X_test.index, 'date_time']
test_data['Actual'] = y_test
test_data['Predicted'] = y_pred

# Sort the data by date_time for proper plotting
test_data.sort_values(by='date_time', inplace=True)

# Visualize the results in a plot
plt.figure(figsize=(14, 8))
plt.plot(test_data['date_time'], test_data['Actual'], label='Valor Real', color='blue')
plt.plot(test_data['date_time'], test_data['Predicted'], label='Valor Previsto', color='red', linestyle='--')
plt.xlabel('Data')
plt.ylabel('Valor')
plt.title('Comparação de Valores Reais e Previstos ao Longo do Tempo')
plt.legend()
plt.show()

# Predict the next 4 days' closing values
predictions = []
last_date = data['date_time'].max()

# Prepare the initial feature set for the next day's prediction
next_day_features = data.iloc[-1].copy()

for i in range(1, 5):
    next_date = last_date + pd.Timedelta(days=i)
    next_date_unix = next_date.value // 10**9

    # Update the date_time for the next day
    next_day_features['date_time'] = next_date_unix

    # Convert the features to a DataFrame
    next_day_features_df = pd.DataFrame([next_day_features])

    # Make the prediction
    next_day_prediction = ridge_model.predict(next_day_features_df.drop(columns=['close']))[0]

    # Store the prediction
    predictions.append((next_date, next_day_prediction))

    # Update the features for the next iteration
    next_day_features['close'] = next_day_prediction

# Print predictions for the next 4 days
for date, prediction in predictions:
    print(f'Previsão para {date.date()}: {prediction:.2f}')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

data = pd.read_csv('BTCUSDT_1D (2).csv')

# Converter a coluna 'date_time' para timestamp Unix
data['date_time'] = pd.to_datetime(data['date_time'], dayfirst=True).view(int) // 10**9

# Identificar colunas categóricas
categorical_cols = data.select_dtypes(include=['object']).columns

# Converter colunas categóricas para numéricas usando one-hot encoding
data = pd.get_dummies(data, columns=categorical_cols)

# Tratar valores ausentes imputando com a média da coluna
data.fillna(data.mean(), inplace=True)

# Separar as variáveis independentes (X) e a variável dependente (y)
X = data.drop(columns=['close'])  # Colunas independentes (exceto 'close')
y = data['close']  # Coluna 'close' como variável dependente

# Dividir os dados em conjuntos de treino (60%) e teste (40%) baseados em índices
split_index = int(len(data) * 0.6)
X_train, X_test = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]

# Criar o modelo de regressão Ridge
alpha = 1.0  # Hiperparâmetro de regularização (ajuste conforme necessário)
ridge_model = Ridge(alpha=alpha)

# Treinar o modelo
ridge_model.fit(X_train, y_train)

# Fazer previsões no conjunto de treino
y_train_pred = ridge_model.predict(X_train)

# Fazer previsões no conjunto de teste
y_test_pred = ridge_model.predict(X_test)

# Avaliar a performance do modelo (erro quadrático médio)
train_mse = mean_squared_error(y_train, y_train_pred)
test_mse = mean_squared_error(y_test, y_test_pred)
train_rmse = np.sqrt(train_mse)
test_rmse = np.sqrt(test_mse)

print(f'Train RMSE: {train_rmse:.2f}')
print(f'Test RMSE: {test_rmse:.2f}')

# Converter a coluna 'date_time' de volta para datetime para plotagem
data['date_time'] = pd.to_datetime(data['date_time'], unit='s')

# Mesclar previsões com os conjuntos de treino e teste para plotagem
train_data = X_train.copy()
train_data['date_time'] = data.loc[X_train.index, 'date_time']
train_data['Predicted'] = y_train_pred

test_data = X_test.copy()
test_data['date_time'] = data.loc[X_test.index, 'date_time']
test_data['Predicted'] = y_test_pred

# Ordenar os dados por date_time para plotagem adequada
train_data.sort_values(by='date_time', inplace=True)
test_data.sort_values(by='date_time', inplace=True)

# Visualizar os resultados em um gráfico
plt.figure(figsize=(14, 8))

# Plotar dados reais
plt.plot(data['date_time'], y, label='Valor Real', color='green', alpha=0.6)

# Plotar dados de treino previstos
plt.plot(train_data['date_time'], train_data['Predicted'], label='Treino', color='blue', alpha=0.6)

# Plotar dados de teste previstos
plt.plot(test_data['date_time'], test_data['Predicted'], label='Teste', color='red', alpha=0.6)

plt.xlabel('Data')
plt.ylabel('Valor')
plt.title('Comparação de Valores Reais e Previstos (Treino e Teste)')
plt.legend()
plt.show()

